"""
çƒ­æ°´å™¨å¼€å…³å£°éŸ³æ£€æµ‹å™¨ - ä½¿ç”¨ç¤ºä¾‹
"""

from huggingface_hub import hf_hub_download
import torch
import torchaudio
from transformers import Wav2Vec2Model

def load_model(repo_id="your-username/heater-switch-detector"):
    """åŠ è½½æ¨¡å‹"""
    
    print("ğŸ“¥ ä¸‹è½½æ¨¡å‹...")
    model_path = hf_hub_download(
        repo_id=repo_id,
        filename="switch_detector_model.pth"
    )
    
    print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    checkpoint = torch.load(model_path, map_location=device)
    
    # é‡å»ºæ¨¡å‹æ¶æ„
    wav2vec2_model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
    classifier = torch.nn.Sequential(
        torch.nn.Linear(768, 256),
        torch.nn.ReLU(),
        torch.nn.Dropout(0.3),
        torch.nn.Linear(256, 2)
    )
    
    # åŠ è½½æƒé‡
    classifier.load_state_dict(checkpoint['classifier_state_dict'])
    classifier.eval()
    wav2vec2_model.eval()
    
    return wav2vec2_model, classifier

def predict_audio(audio_path, wav2vec2_model, classifier):
    """é¢„æµ‹éŸ³é¢‘"""
    
    # åŠ è½½éŸ³é¢‘
    waveform, sample_rate = torchaudio.load(audio_path)
    
    # é‡é‡‡æ ·åˆ°16kHz
    if sample_rate != 16000:
        resampler = torchaudio.transforms.Resample(sample_rate, 16000)
        waveform = resampler(waveform)
    
    # è½¬ä¸ºå•å£°é“
    if waveform.shape[0] > 1:
        waveform = waveform.mean(dim=0, keepdim=True)
    
    # ç‰¹å¾æå–å’Œé¢„æµ‹
    with torch.no_grad():
        features = wav2vec2_model(waveform).last_hidden_state
        pooled_features = features.mean(dim=1)
        logits = classifier(pooled_features)
        probabilities = torch.softmax(logits, dim=-1)
        prediction = torch.argmax(probabilities, dim=-1)
    
    return {
        'prediction': 'å¼€å…³æŒ‰ä¸‹' if prediction.item() == 1 else 'èƒŒæ™¯å£°éŸ³',
        'confidence': probabilities.max().item(),
        'probabilities': {
            'èƒŒæ™¯å£°éŸ³': probabilities[0][0].item(),
            'å¼€å…³æŒ‰ä¸‹': probabilities[0][1].item()
        }
    }

if __name__ == "__main__":
    # åŠ è½½æ¨¡å‹
    wav2vec2_model, classifier = load_model()
    
    # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_file = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
    
    if test_file and os.path.exists(test_file):
        result = predict_audio(test_file, wav2vec2_model, classifier)
        print(f"\nğŸ¯ é¢„æµ‹ç»“æœ: {result['prediction']}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"ğŸ“ˆ è¯¦ç»†æ¦‚ç‡:")
        for label, prob in result['probabilities'].items():
            print(f"   {label}: {prob:.3f}")
    else:
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
